\babel@toc {polish}{}\relax 
\contentsline {section}{\numberline {1}Wstęp}{3}{section.1}%
\contentsline {subsection}{\numberline {1.1}Motywacja}{3}{subsection.1.1}%
\contentsline {subsection}{\numberline {1.2}Nawiązanie do natury}{3}{subsection.1.2}%
\contentsline {subsection}{\numberline {1.3}Intuicja}{3}{subsection.1.3}%
\contentsline {section}{\numberline {2}Historia nauczania przez wzmacnianie}{4}{section.2}%
\contentsline {subsection}{\numberline {2.1}Początki}{4}{subsection.2.1}%
\contentsline {subsection}{\numberline {2.2}Odrodzenie}{4}{subsection.2.2}%
\contentsline {subsection}{\numberline {2.3}Historia zastosowań w grach}{5}{subsection.2.3}%
\contentsline {section}{\numberline {3}Czym jest nauczanie przez wzmacnianie}{6}{section.3}%
\contentsline {subsection}{\numberline {3.1}Nauczanie nadzorowane}{6}{subsection.3.1}%
\contentsline {subsection}{\numberline {3.2}Nauczanie nienadzorowane}{6}{subsection.3.2}%
\contentsline {subsection}{\numberline {3.3}Nauczanie sekwencyjne}{7}{subsection.3.3}%
\contentsline {section}{\numberline {4}Elementy nauczania przez wzmacnianie}{7}{section.4}%
\contentsline {subsection}{\numberline {4.1}Polityka}{8}{subsection.4.1}%
\contentsline {subsection}{\numberline {4.2}Nagrody}{8}{subsection.4.2}%
\contentsline {subsection}{\numberline {4.3}Funkcja wartości}{8}{subsection.4.3}%
\contentsline {subsection}{\numberline {4.4}Model środowiska}{9}{subsection.4.4}%
\contentsline {section}{\numberline {5}Przykład nauczania przez wzmacnianie}{9}{section.5}%
\contentsline {subsection}{\numberline {5.1}Gra w szachy}{9}{subsection.5.1}%
\contentsline {subsection}{\numberline {5.2}Robot sprzątający}{10}{subsection.5.2}%
\contentsline {subsection}{\numberline {5.3}System rekomendacji (np. Youtube, Netflix)}{10}{subsection.5.3}%
\contentsline {section}{\numberline {6}Proces decyzyjny Markowa}{10}{section.6}%
\contentsline {subsection}{\numberline {6.1}Elementy MDP}{10}{subsection.6.1}%
\contentsline {subsection}{\numberline {6.2}Własność Markowa}{11}{subsection.6.2}%
\contentsline {section}{\numberline {7}Polityka - Podejście Tabularyczne}{11}{section.7}%
\contentsline {subsection}{\numberline {7.1}Q-Tabela}{11}{subsection.7.1}%
\contentsline {subsection}{\numberline {7.2}Aktualizowanie wartości Q-Tabeli}{12}{subsection.7.2}%
\contentsline {subsubsection}{\numberline {7.2.1}Natychmiastowa nagroda}{12}{subsubsection.7.2.1}%
\contentsline {subsubsection}{\numberline {7.2.2}Przyszłe nagrody}{12}{subsubsection.7.2.2}%
\contentsline {subsubsection}{\numberline {7.2.3}Waga przyszłych nagród - Współczynnik dyskontowania}{13}{subsubsection.7.2.3}%
\contentsline {subsubsection}{\numberline {7.2.4}Współczynnik uczenia}{14}{subsubsection.7.2.4}%
\contentsline {subsubsection}{\numberline {7.2.5}Równanie Bellmana}{15}{subsubsection.7.2.5}%
\contentsline {section}{\numberline {8}Eksploracja, Eksploatacja}{15}{section.8}%
\contentsline {subsection}{\numberline {8.1}Współczynnik eksploracji}{15}{subsection.8.1}%
\contentsline {subsection}{\numberline {8.2}Zmiana współczynnika eksploracji podczas uczenia}{16}{subsection.8.2}%
\contentsline {section}{\numberline {9}Polityka jako sieć neuronowa - Deep Reinforcement Learning}{17}{section.9}%
\contentsline {subsection}{\numberline {9.1}Deep Q-Network}{17}{subsection.9.1}%
